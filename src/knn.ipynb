{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90e008e2",
   "metadata": {},
   "source": [
    "## Train a K-Nearest Neighbors Model\n",
    "The model will be trained using pandas and scikit-learn.\n",
    "The model will be trained from data found at https://www.kaggle.com/datasets/imakash3011/customer-personality-analysis\n",
    "\n",
    "I am running this through VS Code, using a docker container. You may also use the `ipynb` file in other Jupyter Notebook style setups. Consult Jupyter Notebook for options."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f74fe5",
   "metadata": {},
   "source": [
    "**To download the data, run this cell.**\n",
    "\n",
    "Running this cell will download the data, if you are running it in the docker container. If not, you will need to navigate to the `KAGGLE_DATA_URL` and download the data manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62fa9e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/MS365/src/data/knn contains data. Delete the file(s) if you want to download again.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from data import download_kaggle_dataset\n",
    "KAGGLE_DATA_URL = \"https://www.kaggle.com/datasets/imakash3011/customer-personality-analysis\"\n",
    "DATA_PATH = os.path.join(os.getcwd(), \"data\", \"knn\")\n",
    "download_kaggle_dataset(KAGGLE_DATA_URL, DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6468bf22",
   "metadata": {},
   "source": [
    "**Import the necessary python packages**\n",
    "\n",
    "Import `pandas`, `sklearn.model_selection.train_test_split`, `sklearn.preprocessing.MinMaxScaler`, `sklearn.neighbors.KNeighborsClassifier`, `sklearn.metrics.accuracy_score`, `sklearn.metrics.classification_report`, `imblearn.over_sampling.RandomOverSampler` and `matplotlib.pyplot`. Typically, packages such as `pandas` and `matplotlib.pyplot` are imported with an allias. I will not be following that strategy here. \n",
    "\n",
    "The default size of the plots from `matplotlib.pyplot` is 6.4 inches by 4.8 inches ([width by height](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.figure.html)). I wll be setting them to 20 inches by 5 inches. This will create a more readable output. Depending on your screen size, you may want to change this for your own use. \n",
    "\n",
    "By default, `pandas` will truncate datasets with a lot of rows and a lot of columns. You can alter this functionality with the `set_options()` function. I have set it to show all possible columns. This could result in long run times for cells where you are displaying the data, if there are many columns to display. This will be expected behavior for this analysis.\n",
    "\n",
    "If you are running the docker container or if you are using [Google Colab](https://colab.research.google.com/), the `pip install` has already been done. If not, then please consult your jupyter notebook environment docs for how to install the needed packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a3090e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import matplotlib.pyplot\n",
    "\n",
    "matplotlib.pyplot.rcParams['figure.figsize'] = [20, 5]\n",
    "pandas.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126ad957",
   "metadata": {},
   "source": [
    "**Import the data for analysis**\n",
    "\n",
    "The file used for analysis is `marketing_campaign.csv`. If you used the above cell for downloading the file, the data will be in `/data/knn`. The file is a tab-delimited file, even though it was saved as a .CSV file by the Kaggle user. To load this using pandas, use the `sep=` parameter and specify that the separator will be the tab, which is represented as `\\t`.\n",
    "\n",
    "It is good practice to display the top rows of your dataset to verify that everything imported correctly and to get eyes on what the data are. Use the `head()` method to look at the top 5 rows of data. If you want to see more data, you can use the `n=` parameter and pass in a value. I have used 15, to see the top 15 rows of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee39f8bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Year_Birth</th>\n",
       "      <th>Education</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Income</th>\n",
       "      <th>Kidhome</th>\n",
       "      <th>Teenhome</th>\n",
       "      <th>Dt_Customer</th>\n",
       "      <th>Recency</th>\n",
       "      <th>MntWines</th>\n",
       "      <th>MntFruits</th>\n",
       "      <th>MntMeatProducts</th>\n",
       "      <th>MntFishProducts</th>\n",
       "      <th>MntSweetProducts</th>\n",
       "      <th>MntGoldProds</th>\n",
       "      <th>NumDealsPurchases</th>\n",
       "      <th>NumWebPurchases</th>\n",
       "      <th>NumCatalogPurchases</th>\n",
       "      <th>NumStorePurchases</th>\n",
       "      <th>NumWebVisitsMonth</th>\n",
       "      <th>AcceptedCmp3</th>\n",
       "      <th>AcceptedCmp4</th>\n",
       "      <th>AcceptedCmp5</th>\n",
       "      <th>AcceptedCmp1</th>\n",
       "      <th>AcceptedCmp2</th>\n",
       "      <th>Complain</th>\n",
       "      <th>Z_CostContact</th>\n",
       "      <th>Z_Revenue</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5524</td>\n",
       "      <td>1957</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Single</td>\n",
       "      <td>58138.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>04-09-2012</td>\n",
       "      <td>58</td>\n",
       "      <td>635</td>\n",
       "      <td>88</td>\n",
       "      <td>546</td>\n",
       "      <td>172</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2174</td>\n",
       "      <td>1954</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Single</td>\n",
       "      <td>46344.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>08-03-2014</td>\n",
       "      <td>38</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4141</td>\n",
       "      <td>1965</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Together</td>\n",
       "      <td>71613.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21-08-2013</td>\n",
       "      <td>26</td>\n",
       "      <td>426</td>\n",
       "      <td>49</td>\n",
       "      <td>127</td>\n",
       "      <td>111</td>\n",
       "      <td>21</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6182</td>\n",
       "      <td>1984</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Together</td>\n",
       "      <td>26646.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10-02-2014</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5324</td>\n",
       "      <td>1981</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Married</td>\n",
       "      <td>58293.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19-01-2014</td>\n",
       "      <td>94</td>\n",
       "      <td>173</td>\n",
       "      <td>43</td>\n",
       "      <td>118</td>\n",
       "      <td>46</td>\n",
       "      <td>27</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7446</td>\n",
       "      <td>1967</td>\n",
       "      <td>Master</td>\n",
       "      <td>Together</td>\n",
       "      <td>62513.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>09-09-2013</td>\n",
       "      <td>16</td>\n",
       "      <td>520</td>\n",
       "      <td>42</td>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>965</td>\n",
       "      <td>1971</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>55635.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13-11-2012</td>\n",
       "      <td>34</td>\n",
       "      <td>235</td>\n",
       "      <td>65</td>\n",
       "      <td>164</td>\n",
       "      <td>50</td>\n",
       "      <td>49</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6177</td>\n",
       "      <td>1985</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Married</td>\n",
       "      <td>33454.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>08-05-2013</td>\n",
       "      <td>32</td>\n",
       "      <td>76</td>\n",
       "      <td>10</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4855</td>\n",
       "      <td>1974</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Together</td>\n",
       "      <td>30351.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>06-06-2013</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5899</td>\n",
       "      <td>1950</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Together</td>\n",
       "      <td>5648.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13-03-2014</td>\n",
       "      <td>68</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1994</td>\n",
       "      <td>1983</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15-11-2013</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>387</td>\n",
       "      <td>1976</td>\n",
       "      <td>Basic</td>\n",
       "      <td>Married</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13-11-2012</td>\n",
       "      <td>59</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2125</td>\n",
       "      <td>1959</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>63033.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15-11-2013</td>\n",
       "      <td>82</td>\n",
       "      <td>194</td>\n",
       "      <td>61</td>\n",
       "      <td>480</td>\n",
       "      <td>225</td>\n",
       "      <td>112</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8180</td>\n",
       "      <td>1952</td>\n",
       "      <td>Master</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>59354.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15-11-2013</td>\n",
       "      <td>53</td>\n",
       "      <td>233</td>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2569</td>\n",
       "      <td>1987</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Married</td>\n",
       "      <td>17323.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10-10-2012</td>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  Year_Birth   Education Marital_Status   Income  Kidhome  Teenhome  \\\n",
       "0   5524        1957  Graduation         Single  58138.0        0         0   \n",
       "1   2174        1954  Graduation         Single  46344.0        1         1   \n",
       "2   4141        1965  Graduation       Together  71613.0        0         0   \n",
       "3   6182        1984  Graduation       Together  26646.0        1         0   \n",
       "4   5324        1981         PhD        Married  58293.0        1         0   \n",
       "5   7446        1967      Master       Together  62513.0        0         1   \n",
       "6    965        1971  Graduation       Divorced  55635.0        0         1   \n",
       "7   6177        1985         PhD        Married  33454.0        1         0   \n",
       "8   4855        1974         PhD       Together  30351.0        1         0   \n",
       "9   5899        1950         PhD       Together   5648.0        1         1   \n",
       "10  1994        1983  Graduation        Married      NaN        1         0   \n",
       "11   387        1976       Basic        Married   7500.0        0         0   \n",
       "12  2125        1959  Graduation       Divorced  63033.0        0         0   \n",
       "13  8180        1952      Master       Divorced  59354.0        1         1   \n",
       "14  2569        1987  Graduation        Married  17323.0        0         0   \n",
       "\n",
       "   Dt_Customer  Recency  MntWines  MntFruits  MntMeatProducts  \\\n",
       "0   04-09-2012       58       635         88              546   \n",
       "1   08-03-2014       38        11          1                6   \n",
       "2   21-08-2013       26       426         49              127   \n",
       "3   10-02-2014       26        11          4               20   \n",
       "4   19-01-2014       94       173         43              118   \n",
       "5   09-09-2013       16       520         42               98   \n",
       "6   13-11-2012       34       235         65              164   \n",
       "7   08-05-2013       32        76         10               56   \n",
       "8   06-06-2013       19        14          0               24   \n",
       "9   13-03-2014       68        28          0                6   \n",
       "10  15-11-2013       11         5          5                6   \n",
       "11  13-11-2012       59         6         16               11   \n",
       "12  15-11-2013       82       194         61              480   \n",
       "13  15-11-2013       53       233          2               53   \n",
       "14  10-10-2012       38         3         14               17   \n",
       "\n",
       "    MntFishProducts  MntSweetProducts  MntGoldProds  NumDealsPurchases  \\\n",
       "0               172                88            88                  3   \n",
       "1                 2                 1             6                  2   \n",
       "2               111                21            42                  1   \n",
       "3                10                 3             5                  2   \n",
       "4                46                27            15                  5   \n",
       "5                 0                42            14                  2   \n",
       "6                50                49            27                  4   \n",
       "7                 3                 1            23                  2   \n",
       "8                 3                 3             2                  1   \n",
       "9                 1                 1            13                  1   \n",
       "10                0                 2             1                  1   \n",
       "11               11                 1            16                  1   \n",
       "12              225               112            30                  1   \n",
       "13                3                 5            14                  3   \n",
       "14                6                 1             5                  1   \n",
       "\n",
       "    NumWebPurchases  NumCatalogPurchases  NumStorePurchases  \\\n",
       "0                 8                   10                  4   \n",
       "1                 1                    1                  2   \n",
       "2                 8                    2                 10   \n",
       "3                 2                    0                  4   \n",
       "4                 5                    3                  6   \n",
       "5                 6                    4                 10   \n",
       "6                 7                    3                  7   \n",
       "7                 4                    0                  4   \n",
       "8                 3                    0                  2   \n",
       "9                 1                    0                  0   \n",
       "10                1                    0                  2   \n",
       "11                2                    0                  3   \n",
       "12                3                    4                  8   \n",
       "13                6                    1                  5   \n",
       "14                1                    0                  3   \n",
       "\n",
       "    NumWebVisitsMonth  AcceptedCmp3  AcceptedCmp4  AcceptedCmp5  AcceptedCmp1  \\\n",
       "0                   7             0             0             0             0   \n",
       "1                   5             0             0             0             0   \n",
       "2                   4             0             0             0             0   \n",
       "3                   6             0             0             0             0   \n",
       "4                   5             0             0             0             0   \n",
       "5                   6             0             0             0             0   \n",
       "6                   6             0             0             0             0   \n",
       "7                   8             0             0             0             0   \n",
       "8                   9             0             0             0             0   \n",
       "9                  20             1             0             0             0   \n",
       "10                  7             0             0             0             0   \n",
       "11                  8             0             0             0             0   \n",
       "12                  2             0             0             0             0   \n",
       "13                  6             0             0             0             0   \n",
       "14                  8             0             0             0             0   \n",
       "\n",
       "    AcceptedCmp2  Complain  Z_CostContact  Z_Revenue  Response  \n",
       "0              0         0              3         11         1  \n",
       "1              0         0              3         11         0  \n",
       "2              0         0              3         11         0  \n",
       "3              0         0              3         11         0  \n",
       "4              0         0              3         11         0  \n",
       "5              0         0              3         11         0  \n",
       "6              0         0              3         11         0  \n",
       "7              0         0              3         11         0  \n",
       "8              0         0              3         11         1  \n",
       "9              0         0              3         11         0  \n",
       "10             0         0              3         11         0  \n",
       "11             0         0              3         11         0  \n",
       "12             0         0              3         11         0  \n",
       "13             0         0              3         11         0  \n",
       "14             0         0              3         11         0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pandas.read_csv(os.path.join(DATA_PATH, \"marketing_campaign.csv\"), sep=\"\\t\")\n",
    "df.head(n=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c29ff84",
   "metadata": {},
   "source": [
    "**Clean the data**\n",
    "\n",
    "K-Nearest Neighbors (KNN) is a classification algorithm. The premise of KNN is that data can be grouped together based on how similar the data points are to those around it. The similarity of the data points is decided by a distance equation. There are many distance equations to choose from, but the most common to use, and the one that will be used in this analysis, is the Euclidean Distance formula $d = \\sqrt{(x_1 - x_2)^2 + (y_1 - y_2)^2}$ (cosine distance is commonly used in training large language models like ChatGPT). KNN is a non-parametric statistical model and does not hold any assumptions about the data on which it is used. The only requirement of the data is that it is numerical and not categorical.\n",
    "\n",
    "The data from `marketing_campaign.csv`, shown above, contains a number of categorical data columns that will need to be cleaned before the KNN model can be trained and evaluated. The categorical data could be converted to numerical data through a number of encoding processes, but those methods will not be explored with this model. Instead, the categorical columns will be dropped.\n",
    "\n",
    "The columns that contain categorical data are `ID`, `Year_Birth`, `Education`, `Marital_Status`, and `Dt_Customer`. Using the [`drop()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html) method on the DataFrame will drop the specified columns. Make sure to include the parameter `inplace=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d466361c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"ID\", \"Year_Birth\", \"Education\", \"Marital_Status\", \"Dt_Customer\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0b7cc6",
   "metadata": {},
   "source": [
    "The specific data types in your DataFrame `df` need to be numerical. Run the `dtypes` attribute on `df` to verify that all remaining columns are numeric data types. The numeric data type options are `int` and `float`. You may also see `int64` and `float64`, which fall in the `int` and `float` data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e1edac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Income                 float64\n",
       "Kidhome                  int64\n",
       "Teenhome                 int64\n",
       "Recency                  int64\n",
       "MntWines                 int64\n",
       "MntFruits                int64\n",
       "MntMeatProducts          int64\n",
       "MntFishProducts          int64\n",
       "MntSweetProducts         int64\n",
       "MntGoldProds             int64\n",
       "NumDealsPurchases        int64\n",
       "NumWebPurchases          int64\n",
       "NumCatalogPurchases      int64\n",
       "NumStorePurchases        int64\n",
       "NumWebVisitsMonth        int64\n",
       "AcceptedCmp3             int64\n",
       "AcceptedCmp4             int64\n",
       "AcceptedCmp5             int64\n",
       "AcceptedCmp1             int64\n",
       "AcceptedCmp2             int64\n",
       "Complain                 int64\n",
       "Z_CostContact            int64\n",
       "Z_Revenue                int64\n",
       "Response                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0c4818",
   "metadata": {},
   "source": [
    "Run the `describe()` method on `df` to verify that there are not any missing values in the many columns. \n",
    "\n",
    "Most columns show 2,240 rows of data. The `Income` column shows 2,216 rows of data. The count is the number of non-null values. Since there are only 2,216 rows of non-null values in the `Income` column, it will be necessary to fill those values with a value. A common strategy is to use the median, mean, or mode to fill in missing data. This provides data for every row without altering the statistics of the column too much.\n",
    "\n",
    "Looking at the output for `describe()`, the mean and the median are displayed. The median is the value at the 50% or 50th percentile. Those two values are very similar to each other, so using the mean or the median could be a good strategy for filling in the missing values. It is possible that there is a better method for filling in the missing data, but that will not be explored at this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b99c391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Kidhome</th>\n",
       "      <th>Teenhome</th>\n",
       "      <th>Recency</th>\n",
       "      <th>MntWines</th>\n",
       "      <th>MntFruits</th>\n",
       "      <th>MntMeatProducts</th>\n",
       "      <th>MntFishProducts</th>\n",
       "      <th>MntSweetProducts</th>\n",
       "      <th>MntGoldProds</th>\n",
       "      <th>NumDealsPurchases</th>\n",
       "      <th>NumWebPurchases</th>\n",
       "      <th>NumCatalogPurchases</th>\n",
       "      <th>NumStorePurchases</th>\n",
       "      <th>NumWebVisitsMonth</th>\n",
       "      <th>AcceptedCmp3</th>\n",
       "      <th>AcceptedCmp4</th>\n",
       "      <th>AcceptedCmp5</th>\n",
       "      <th>AcceptedCmp1</th>\n",
       "      <th>AcceptedCmp2</th>\n",
       "      <th>Complain</th>\n",
       "      <th>Z_CostContact</th>\n",
       "      <th>Z_Revenue</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2216.000000</td>\n",
       "      <td>2240.000000</td>\n",
       "      <td>2240.000000</td>\n",
       "      <td>2240.000000</td>\n",
       "      <td>2240.000000</td>\n",
       "      <td>2240.000000</td>\n",
       "      <td>2240.000000</td>\n",
       "      <td>2240.000000</td>\n",
       "      <td>2240.000000</td>\n",
       "      <td>2240.000000</td>\n",
       "      <td>2240.000000</td>\n",
       "      <td>2240.000000</td>\n",
       "      <td>2240.000000</td>\n",
       "      <td>2240.000000</td>\n",
       "      <td>2240.000000</td>\n",
       "      <td>2240.000000</td>\n",
       "      <td>2240.000000</td>\n",
       "      <td>2240.000000</td>\n",
       "      <td>2240.000000</td>\n",
       "      <td>2240.000000</td>\n",
       "      <td>2240.000000</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>2240.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>52247.251354</td>\n",
       "      <td>0.444196</td>\n",
       "      <td>0.506250</td>\n",
       "      <td>49.109375</td>\n",
       "      <td>303.935714</td>\n",
       "      <td>26.302232</td>\n",
       "      <td>166.950000</td>\n",
       "      <td>37.525446</td>\n",
       "      <td>27.062946</td>\n",
       "      <td>44.021875</td>\n",
       "      <td>2.325000</td>\n",
       "      <td>4.084821</td>\n",
       "      <td>2.662054</td>\n",
       "      <td>5.790179</td>\n",
       "      <td>5.316518</td>\n",
       "      <td>0.072768</td>\n",
       "      <td>0.074554</td>\n",
       "      <td>0.072768</td>\n",
       "      <td>0.064286</td>\n",
       "      <td>0.013393</td>\n",
       "      <td>0.009375</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.149107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>25173.076661</td>\n",
       "      <td>0.538398</td>\n",
       "      <td>0.544538</td>\n",
       "      <td>28.962453</td>\n",
       "      <td>336.597393</td>\n",
       "      <td>39.773434</td>\n",
       "      <td>225.715373</td>\n",
       "      <td>54.628979</td>\n",
       "      <td>41.280498</td>\n",
       "      <td>52.167439</td>\n",
       "      <td>1.932238</td>\n",
       "      <td>2.778714</td>\n",
       "      <td>2.923101</td>\n",
       "      <td>3.250958</td>\n",
       "      <td>2.426645</td>\n",
       "      <td>0.259813</td>\n",
       "      <td>0.262728</td>\n",
       "      <td>0.259813</td>\n",
       "      <td>0.245316</td>\n",
       "      <td>0.114976</td>\n",
       "      <td>0.096391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.356274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1730.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>35303.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>23.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>51381.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>173.500000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>68522.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>504.250000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>232.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>666666.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>1493.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>1725.000000</td>\n",
       "      <td>259.000000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>362.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Income      Kidhome     Teenhome      Recency     MntWines  \\\n",
       "count    2216.000000  2240.000000  2240.000000  2240.000000  2240.000000   \n",
       "mean    52247.251354     0.444196     0.506250    49.109375   303.935714   \n",
       "std     25173.076661     0.538398     0.544538    28.962453   336.597393   \n",
       "min      1730.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%     35303.000000     0.000000     0.000000    24.000000    23.750000   \n",
       "50%     51381.500000     0.000000     0.000000    49.000000   173.500000   \n",
       "75%     68522.000000     1.000000     1.000000    74.000000   504.250000   \n",
       "max    666666.000000     2.000000     2.000000    99.000000  1493.000000   \n",
       "\n",
       "         MntFruits  MntMeatProducts  MntFishProducts  MntSweetProducts  \\\n",
       "count  2240.000000      2240.000000      2240.000000       2240.000000   \n",
       "mean     26.302232       166.950000        37.525446         27.062946   \n",
       "std      39.773434       225.715373        54.628979         41.280498   \n",
       "min       0.000000         0.000000         0.000000          0.000000   \n",
       "25%       1.000000        16.000000         3.000000          1.000000   \n",
       "50%       8.000000        67.000000        12.000000          8.000000   \n",
       "75%      33.000000       232.000000        50.000000         33.000000   \n",
       "max     199.000000      1725.000000       259.000000        263.000000   \n",
       "\n",
       "       MntGoldProds  NumDealsPurchases  NumWebPurchases  NumCatalogPurchases  \\\n",
       "count   2240.000000        2240.000000      2240.000000          2240.000000   \n",
       "mean      44.021875           2.325000         4.084821             2.662054   \n",
       "std       52.167439           1.932238         2.778714             2.923101   \n",
       "min        0.000000           0.000000         0.000000             0.000000   \n",
       "25%        9.000000           1.000000         2.000000             0.000000   \n",
       "50%       24.000000           2.000000         4.000000             2.000000   \n",
       "75%       56.000000           3.000000         6.000000             4.000000   \n",
       "max      362.000000          15.000000        27.000000            28.000000   \n",
       "\n",
       "       NumStorePurchases  NumWebVisitsMonth  AcceptedCmp3  AcceptedCmp4  \\\n",
       "count        2240.000000        2240.000000   2240.000000   2240.000000   \n",
       "mean            5.790179           5.316518      0.072768      0.074554   \n",
       "std             3.250958           2.426645      0.259813      0.262728   \n",
       "min             0.000000           0.000000      0.000000      0.000000   \n",
       "25%             3.000000           3.000000      0.000000      0.000000   \n",
       "50%             5.000000           6.000000      0.000000      0.000000   \n",
       "75%             8.000000           7.000000      0.000000      0.000000   \n",
       "max            13.000000          20.000000      1.000000      1.000000   \n",
       "\n",
       "       AcceptedCmp5  AcceptedCmp1  AcceptedCmp2     Complain  Z_CostContact  \\\n",
       "count   2240.000000   2240.000000   2240.000000  2240.000000         2240.0   \n",
       "mean       0.072768      0.064286      0.013393     0.009375            3.0   \n",
       "std        0.259813      0.245316      0.114976     0.096391            0.0   \n",
       "min        0.000000      0.000000      0.000000     0.000000            3.0   \n",
       "25%        0.000000      0.000000      0.000000     0.000000            3.0   \n",
       "50%        0.000000      0.000000      0.000000     0.000000            3.0   \n",
       "75%        0.000000      0.000000      0.000000     0.000000            3.0   \n",
       "max        1.000000      1.000000      1.000000     1.000000            3.0   \n",
       "\n",
       "       Z_Revenue     Response  \n",
       "count     2240.0  2240.000000  \n",
       "mean        11.0     0.149107  \n",
       "std          0.0     0.356274  \n",
       "min         11.0     0.000000  \n",
       "25%         11.0     0.000000  \n",
       "50%         11.0     0.000000  \n",
       "75%         11.0     0.000000  \n",
       "max         11.0     1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a689b7d0",
   "metadata": {},
   "source": [
    "Fill in the missing values in the `Income` column with the mean of the column. Use [`fillna`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html) with the mean of `df.Income` for the value and `inplace=True`. Rerunning `df.describe()` will show that all columns now have the same number of counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e40f943e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Kidhome</th>\n",
       "      <th>Teenhome</th>\n",
       "      <th>Recency</th>\n",
       "      <th>MntWines</th>\n",
       "      <th>MntFruits</th>\n",
       "      <th>MntMeatProducts</th>\n",
       "      <th>MntFishProducts</th>\n",
       "      <th>MntSweetProducts</th>\n",
       "      <th>MntGoldProds</th>\n",
       "      <th>NumDealsPurchases</th>\n",
       "      <th>NumWebPurchases</th>\n",
       "      <th>NumCatalogPurchases</th>\n",
       "      <th>NumStorePurchases</th>\n",
       "      <th>NumWebVisitsMonth</th>\n",
       "      <th>AcceptedCmp3</th>\n",
       "      <th>AcceptedCmp4</th>\n",
       "      <th>AcceptedCmp5</th>\n",
       "      <th>AcceptedCmp1</th>\n",
       "      <th>AcceptedCmp2</th>\n",
       "      <th>Complain</th>\n",
       "      <th>Z_CostContact</th>\n",
       "      <th>Z_Revenue</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2240.000000</td>\n",
       "      <td>2240.000000</td>\n",
       "      <td>2240.000000</td>\n",
       "      <td>2240.000000</td>\n",
       "      <td>2240.000000</td>\n",
       "      <td>2240.000000</td>\n",
       "      <td>2240.000000</td>\n",
       "      <td>2240.000000</td>\n",
       "      <td>2240.000000</td>\n",
       "      <td>2240.000000</td>\n",
       "      <td>2240.000000</td>\n",
       "      <td>2240.000000</td>\n",
       "      <td>2240.000000</td>\n",
       "      <td>2240.000000</td>\n",
       "      <td>2240.000000</td>\n",
       "      <td>2240.000000</td>\n",
       "      <td>2240.000000</td>\n",
       "      <td>2240.000000</td>\n",
       "      <td>2240.000000</td>\n",
       "      <td>2240.000000</td>\n",
       "      <td>2240.000000</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>2240.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>52247.251354</td>\n",
       "      <td>0.444196</td>\n",
       "      <td>0.506250</td>\n",
       "      <td>49.109375</td>\n",
       "      <td>303.935714</td>\n",
       "      <td>26.302232</td>\n",
       "      <td>166.950000</td>\n",
       "      <td>37.525446</td>\n",
       "      <td>27.062946</td>\n",
       "      <td>44.021875</td>\n",
       "      <td>2.325000</td>\n",
       "      <td>4.084821</td>\n",
       "      <td>2.662054</td>\n",
       "      <td>5.790179</td>\n",
       "      <td>5.316518</td>\n",
       "      <td>0.072768</td>\n",
       "      <td>0.074554</td>\n",
       "      <td>0.072768</td>\n",
       "      <td>0.064286</td>\n",
       "      <td>0.013393</td>\n",
       "      <td>0.009375</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.149107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>25037.797168</td>\n",
       "      <td>0.538398</td>\n",
       "      <td>0.544538</td>\n",
       "      <td>28.962453</td>\n",
       "      <td>336.597393</td>\n",
       "      <td>39.773434</td>\n",
       "      <td>225.715373</td>\n",
       "      <td>54.628979</td>\n",
       "      <td>41.280498</td>\n",
       "      <td>52.167439</td>\n",
       "      <td>1.932238</td>\n",
       "      <td>2.778714</td>\n",
       "      <td>2.923101</td>\n",
       "      <td>3.250958</td>\n",
       "      <td>2.426645</td>\n",
       "      <td>0.259813</td>\n",
       "      <td>0.262728</td>\n",
       "      <td>0.259813</td>\n",
       "      <td>0.245316</td>\n",
       "      <td>0.114976</td>\n",
       "      <td>0.096391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.356274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1730.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>35538.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>23.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>51741.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>173.500000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>68289.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>504.250000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>232.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>666666.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>1493.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>1725.000000</td>\n",
       "      <td>259.000000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>362.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Income      Kidhome     Teenhome      Recency     MntWines  \\\n",
       "count    2240.000000  2240.000000  2240.000000  2240.000000  2240.000000   \n",
       "mean    52247.251354     0.444196     0.506250    49.109375   303.935714   \n",
       "std     25037.797168     0.538398     0.544538    28.962453   336.597393   \n",
       "min      1730.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%     35538.750000     0.000000     0.000000    24.000000    23.750000   \n",
       "50%     51741.500000     0.000000     0.000000    49.000000   173.500000   \n",
       "75%     68289.750000     1.000000     1.000000    74.000000   504.250000   \n",
       "max    666666.000000     2.000000     2.000000    99.000000  1493.000000   \n",
       "\n",
       "         MntFruits  MntMeatProducts  MntFishProducts  MntSweetProducts  \\\n",
       "count  2240.000000      2240.000000      2240.000000       2240.000000   \n",
       "mean     26.302232       166.950000        37.525446         27.062946   \n",
       "std      39.773434       225.715373        54.628979         41.280498   \n",
       "min       0.000000         0.000000         0.000000          0.000000   \n",
       "25%       1.000000        16.000000         3.000000          1.000000   \n",
       "50%       8.000000        67.000000        12.000000          8.000000   \n",
       "75%      33.000000       232.000000        50.000000         33.000000   \n",
       "max     199.000000      1725.000000       259.000000        263.000000   \n",
       "\n",
       "       MntGoldProds  NumDealsPurchases  NumWebPurchases  NumCatalogPurchases  \\\n",
       "count   2240.000000        2240.000000      2240.000000          2240.000000   \n",
       "mean      44.021875           2.325000         4.084821             2.662054   \n",
       "std       52.167439           1.932238         2.778714             2.923101   \n",
       "min        0.000000           0.000000         0.000000             0.000000   \n",
       "25%        9.000000           1.000000         2.000000             0.000000   \n",
       "50%       24.000000           2.000000         4.000000             2.000000   \n",
       "75%       56.000000           3.000000         6.000000             4.000000   \n",
       "max      362.000000          15.000000        27.000000            28.000000   \n",
       "\n",
       "       NumStorePurchases  NumWebVisitsMonth  AcceptedCmp3  AcceptedCmp4  \\\n",
       "count        2240.000000        2240.000000   2240.000000   2240.000000   \n",
       "mean            5.790179           5.316518      0.072768      0.074554   \n",
       "std             3.250958           2.426645      0.259813      0.262728   \n",
       "min             0.000000           0.000000      0.000000      0.000000   \n",
       "25%             3.000000           3.000000      0.000000      0.000000   \n",
       "50%             5.000000           6.000000      0.000000      0.000000   \n",
       "75%             8.000000           7.000000      0.000000      0.000000   \n",
       "max            13.000000          20.000000      1.000000      1.000000   \n",
       "\n",
       "       AcceptedCmp5  AcceptedCmp1  AcceptedCmp2     Complain  Z_CostContact  \\\n",
       "count   2240.000000   2240.000000   2240.000000  2240.000000         2240.0   \n",
       "mean       0.072768      0.064286      0.013393     0.009375            3.0   \n",
       "std        0.259813      0.245316      0.114976     0.096391            0.0   \n",
       "min        0.000000      0.000000      0.000000     0.000000            3.0   \n",
       "25%        0.000000      0.000000      0.000000     0.000000            3.0   \n",
       "50%        0.000000      0.000000      0.000000     0.000000            3.0   \n",
       "75%        0.000000      0.000000      0.000000     0.000000            3.0   \n",
       "max        1.000000      1.000000      1.000000     1.000000            3.0   \n",
       "\n",
       "       Z_Revenue     Response  \n",
       "count     2240.0  2240.000000  \n",
       "mean        11.0     0.149107  \n",
       "std          0.0     0.356274  \n",
       "min         11.0     0.000000  \n",
       "25%         11.0     0.000000  \n",
       "50%         11.0     0.000000  \n",
       "75%         11.0     0.000000  \n",
       "max         11.0     1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.fillna(value=df.Income.mean(), inplace=True)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c277cd",
   "metadata": {},
   "source": [
    "**Create and Train K-Nearest Neighbors model**\n",
    "\n",
    "KNN is a statistical model that learns as you feed it more data. The thing that we want the model to learn is the `Response` value, based on all the other columns in the dataset. The `Response` column will be our dependent variable, and it will be labeled as `y_column`. The rest of the columns in the dataset will be the independent variables and will be labeled as `x_columns`. The variable `x_columns` is a list of the column names; using the `columns` attribute will provide that information. Using the `remove` function on the `x_columns` variable will remove the `y_column` value from the list.\n",
    "\n",
    "Once the values for the columns has been created, use those values to split `df` into two separate variables. Use `x_columns` to create `x_data` and use `y_column` to create `y_data`. This will be the data used to train the KNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cce2452",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_column = \"Response\"\n",
    "x_columns = list(df.columns)\n",
    "x_columns.remove(y_column)\n",
    "\n",
    "x_data = df[x_columns]\n",
    "y_data = df[y_column]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b89555c",
   "metadata": {},
   "source": [
    "**Normalize the Data**\n",
    "\n",
    "KNN is non-parametric and makes no assumptions about the data. However, it does require numerical data and there will be the assumption that the data follows typical numerical characteristics. Thus, larger numbers are given more weight than smaller numbers. Because of this, our data will likely cause problems for the KNN model because the data are not on the same scale in every column. Reviewing the MAX and MIN values in the `describe` table above will show a lot of variation in those numbers. To account for this, the data should be normalized, fitting it to a specific range scale.\n",
    "\n",
    "Scikit-learn provdes the method [`MinMaxScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) that can be used to normalize the data. `MinMaxScaler` uses a default range of 0-1 for normalization. This is the scale that will be used.\n",
    "\n",
    "Create a variable called `min_max_scale`, which will represent an instance of `MinMaxScaler()`. Pass in the `x_data` variable to the `fit_transform()` method, using `min_max_scale.fit_transform(x_data)`. This will return a data set that has been normalized, where all values will be on a scale from 0 to 1 (the default scale for `MinMaxScaler`). If you were to look at the data output from `MinMaxScaler`, you would see a list of lists of values. That represents the scaled version of the data. Convert it to a dataframe by passing in the `normalized_x` variable to `pandas.DataFrame()`, and specifying the columns as `x_data.columns`. The output of that will be a dataframe. I have assigned the output from `min_max_scale.fit_transform` to `normalized_x` and then I have overwritten `normalized_x` by saving the output of the dataframe to `normalized_x`. This results in a dataframe in `normalized_x` that can be used to train the KNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cb29d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scale = MinMaxScaler()\n",
    "normalized_x = min_max_scale.fit_transform(x_data)\n",
    "normalized_x = pandas.DataFrame(normalized_x, columns=x_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e21175",
   "metadata": {},
   "source": [
    "**Split data into training and testing datasets**\n",
    "\n",
    "The data will need to be split into training datasets and testing datasets. The function `train_test_split` imported from `sklearn.model_selection` can be used to split the data. The function will take the `x_data` and `y_data` and split it into similarly sized datasets. You should consult the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) to get a better understanding of the different parameters that can be passed in.\n",
    "\n",
    "Create variables `x_train`, `x_test`, `y_train`, and `y_test`. The function `train_test_split` will ouput the data to these 4 variables because we used the `x_data` first and the `y_data` second in the parameters of the function.\n",
    "\n",
    "Some key things to keep in mind:\n",
    "1. `train_test_split` will split the data randomly. You should set a seed value for the `random_state` parameter so the random separation is consistent. I have chosen `22`.\n",
    "2. The order you use for your `y_data` and your `x_data` will effect the output data. If you do `train_test_split(y_data, x_data)`, then your output will be y_data before x_data. If you do `train_test_split(x_data, y_data)`, the x_data will be before the y_data.\n",
    "3. A fairly standard choice for the size of your test data is 20% of the total data. If you have more data, you may be able to do a smaller percentage. (more meaning millions of rows of data, or more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abdb2f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(normalized_x, y_data, test_size=0.20, random_state=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de30357",
   "metadata": {},
   "source": [
    "**Create a K-Nearest Neighbors model**\n",
    "\n",
    "Use [`KNeighborsClassifier()`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) to create a KNN model. KNN requires a value for the number of \"neighbors\" to create. The default value in the Sci-kit learn model is 5. A general [rule of thumb](https://mmuratarat.github.io/2019-07-12/k-nn-from-scratch#:~:text=K%2DNN%20algorithm%20is%20an,samples%20in%20the%20training%20dataset.) for the KNN model is to use the square-root of the number of values that are in your dataset ($\\sqrt n$). This would be considered a starting point for training the model and not necessarily the best number of neighbors for the model. The process for finding the best number for neighbors is an iterative process and can require many values before the best one is found. It is also best to use odd numbers for your neighbors value. This avoids instances where there could be a tie between the output of the distance values.\n",
    "\n",
    "The dataset contains 2,240 rows of data. The square-root of 2,240 is approximately 47. For this first iteration, I will use 47 as the number of neighbors. It is likely not the best option, but this will be an iterative process, where the best value for the number of neighbors is determined through testing.\n",
    "\n",
    "The variable `knn` has been created using `KNeighborsClassifier(n_neighbors=k_neighbors).fit(x_train, y_train)`. Chaining the `fit()` method to the creation of the model will result in a trained model.\n",
    "\n",
    "Create a `y_estimates` variable using the `predict()` method. The `y_estimates` variable will be the values predicted by the trained model. \n",
    "\n",
    "*`k_neighbors` will be used many times below, so I have created this here, to reuse later.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "517d0e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_neighbors = 47\n",
    "knn = KNeighborsClassifier(n_neighbors=k_neighbors).fit(x_train, y_train)\n",
    "y_estimates = knn.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f2a391",
   "metadata": {},
   "source": [
    "**Verify the accuracy of the model.**\n",
    "\n",
    "Scikit-learn provides [`accuracy_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) and [`classification_report`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html) from `sklearn.metrics` for verifying the accuracy of the model. \n",
    "\n",
    "Run a `print()` statement around `accuracy_score()` to print the percentage of correctly classified samples. The `accuracy_score` method expects the correct values and the estimated values for your first two parameters. There are other parameters as well, but the default values will be used for this verification. The returning value is ~0.8616, which suggests that our trained model was approximately 86% correct at choosing the correct label. This is a good number. The rule of thumb for an accuracy score is that it be as close to 1.0 as possible, without being 1.0. 86% is likely a very strong value for this model.\n",
    "\n",
    "The second accuracy verification process is `classification_report()`. Pass in the true values and the estimated values to receive a more in depth analysis of the model. The output shows the precision, recall, f1-score, and support for the identified classes: 0 and 1. The following will help to better understand the output and how to interpret it.\n",
    "* Precision: percentage of true-positive lables\n",
    "* Recall: percentage of correctly identified true-positives\n",
    "* F1-Score: calculation of precision and recall, the closer to 1.0, the better\n",
    "* Support: how many examples belong to each class\n",
    "\n",
    "The F1-Score will be the value that is the most interesting for this analysis. It shows .92 for 0 and .34 for 1. This means that the model is very good a picking 1, but not very good at picking 0. The reason for this is likely due to the value in Support. Support shows that there are more 0 values than 1 values, showing that the data are skewed in such a way to provide more examples of 0 than 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "213e29ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.8616071428571429 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.92       375\n",
      "           1       0.76      0.22      0.34        73\n",
      "\n",
      "    accuracy                           0.86       448\n",
      "   macro avg       0.81      0.60      0.63       448\n",
      "weighted avg       0.85      0.86      0.83       448\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score: \", accuracy_score(y_test, y_estimates), \"\\n\")\n",
    "print(classification_report(y_test, y_estimates))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f52742a",
   "metadata": {},
   "source": [
    "**Issues with the KNN model**\n",
    "\n",
    "As mentioned above, there are a couple issues that need to be addressed for this KNN model. The first is that it is possible that 47 is not the correct value for the number of neighbors that need to be used. The second issue is that there are more 0 values in `Response` than there are 1 values. Both of these issues can be addressed relatively easily.\n",
    "\n",
    "To address the unbalanced data issue, use [`RandomOverSampler`](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.RandomOverSampler.html) from `imblearn.over_sampling`. `RandomOverSampler` oversamples the minority class by picking samples at random, and then replacing those values back in the population, allowing them to be resampled. In essence, it creates duplicates of the minority class, at random, creating enough records to match the majority value. For our use, this will increase the number of 1 values to equal that of the 0 values.\n",
    "\n",
    "Create a `RandomOverSampler` model with a `random_state` parameter equal to 17. Here, it has been assigned to the variable `over_sampler`. Use the `over_sampler` variable to `fit_resample()` the `normalized_x` data and the `y_data`. The output has been saved in the variables `x_over` and `y_over`, in that order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b5890c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "over_sampler = RandomOverSampler(random_state=17)\n",
    "x_over, y_over = over_sampler.fit_resample(normalized_x, y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb856e58",
   "metadata": {},
   "source": [
    "The steps for training a new KNN model are the same as were presented above. The difference is now the model will be trained on the `x_over` and `y_over` data. Below, everying that has to do with the oversampled data is labled with `over` to distinguish it from the data used above. The oversampling created more records, as shown in the output of the `classification_report` table, where support now shows 374 values that are 0 and 389 values that are 1. However, the oversampling seems to have worsened the model's effectiveness, based on the Accuracy Score of 0.7824. The f-1 scores show that the model has worsened in predicting 0 values and improved in predicting 1 values, where both are at 78%.\n",
    "\n",
    "This may be a more accurate model even though the accuracy value went down, but since oversampling was used, and the data were copied, it is difficult to know if that is the case. The python package `imblearn` has other methods for sampling data. It may be the case that another method of sampling may provide better results. However, some of the other methods for oversampling have to do with creating synthetic data. This is almost always a bad strategy. There is a lot of literature on why this typically doesn't work. A quick Google search should assist you if this is something that would be of interest. Also, since there are only 2,240 data points, it is possible that there are not enough to get a good analysis. A better analysis may need 100s of thousands of records, or more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8390c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.7824377457404981 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.80      0.78       374\n",
      "           1       0.80      0.76      0.78       389\n",
      "\n",
      "    accuracy                           0.78       763\n",
      "   macro avg       0.78      0.78      0.78       763\n",
      "weighted avg       0.78      0.78      0.78       763\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_over_train, x_over_test, y_over_train, y_over_test = train_test_split(x_over, y_over, test_size=0.20, random_state=22)\n",
    "over_knn = KNeighborsClassifier(n_neighbors=k_neighbors).fit(x_over_train, y_over_train)\n",
    "y_over_estimates = over_knn.predict(x_over_test)\n",
    "print(\"Accuracy Score: \", accuracy_score(y_over_test, y_over_estimates), \"\\n\")\n",
    "print(classification_report(y_over_test, y_over_estimates))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c26e109",
   "metadata": {},
   "source": [
    "In addition to the square-root method mentioned above ($\\sqrt n$) for selecting the number of K, it is also common to plot out a series of accuracy scores and look for the place where the plot drastically changes, or forms an [elbow](https://www.geeksforgeeks.org/elbow-method-for-optimal-value-of-k-in-kmeans/). The process seems simple. Train many models, comparing the accuracy score, and when the amount of change levels out, that is likely the best number of neighbors for the model.\n",
    "\n",
    "This can be done by creating a for-loop, and looping through the model creation process, saving the accuracy score from each trained model. Create a list called `results`. Create a for-loop, looping through the values you want for K. This can be done by using the python-built-in method [`range()`](https://docs.python.org/3/library/functions.html#func-range). The range function can take 3 parameters: start, stop, and step. Typically, step is defaulted to 1 and the function will create a list of values from start to end, steping by 1. Using -1, will mean that the function will step -1 from the start value. Looping through the `range()` values below, will provide a list from 47 to 2, stepping down one value each pass. The rest of the for-loop should look familiar. Create a `KNeighborsClassifier` and train it using the value `k` from the for-loop. The the value of K and the accuracy score to the `results` list as a dictionary value. Pass the `results` list of dictionaries into `pandas.DataFrame` to create a dataframe with the rows and columns of the trained models accuracy score.\n",
    "\n",
    "*I multiplied the accuracy score by 100 to get the average in whole numbers.*\n",
    "\n",
    "Running `results_df` as the final line in this cell will show the values in the `results_df` dataframe, starting with 47 at the top, and ending with 2 at the bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9dfd8bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47</td>\n",
       "      <td>78.243775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>77.588467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45</td>\n",
       "      <td>77.850590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>78.112713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43</td>\n",
       "      <td>78.243775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>42</td>\n",
       "      <td>78.636959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>41</td>\n",
       "      <td>79.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>40</td>\n",
       "      <td>79.554391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>39</td>\n",
       "      <td>79.685452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>38</td>\n",
       "      <td>80.340760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>37</td>\n",
       "      <td>80.602883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>36</td>\n",
       "      <td>80.209699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>35</td>\n",
       "      <td>80.078637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>34</td>\n",
       "      <td>80.209699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>33</td>\n",
       "      <td>80.209699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>32</td>\n",
       "      <td>80.471822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>31</td>\n",
       "      <td>80.471822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>30</td>\n",
       "      <td>80.733945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>29</td>\n",
       "      <td>80.340760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>28</td>\n",
       "      <td>80.865007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>27</td>\n",
       "      <td>80.996068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>26</td>\n",
       "      <td>81.389253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>25</td>\n",
       "      <td>81.782438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>81.651376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>23</td>\n",
       "      <td>82.306684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>22</td>\n",
       "      <td>81.782438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>21</td>\n",
       "      <td>82.175623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20</td>\n",
       "      <td>81.389253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>19</td>\n",
       "      <td>80.733945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>18</td>\n",
       "      <td>80.996068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>17</td>\n",
       "      <td>80.340760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>16</td>\n",
       "      <td>79.554391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>15</td>\n",
       "      <td>79.947575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>14</td>\n",
       "      <td>79.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>13</td>\n",
       "      <td>79.947575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>12</td>\n",
       "      <td>79.947575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>11</td>\n",
       "      <td>79.816514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>10</td>\n",
       "      <td>80.602883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>9</td>\n",
       "      <td>82.699869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>8</td>\n",
       "      <td>83.224115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>7</td>\n",
       "      <td>85.583224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>6</td>\n",
       "      <td>87.680210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>5</td>\n",
       "      <td>88.728702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4</td>\n",
       "      <td>90.170380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>3</td>\n",
       "      <td>92.267366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2</td>\n",
       "      <td>94.102228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     k   accuracy\n",
       "0   47  78.243775\n",
       "1   46  77.588467\n",
       "2   45  77.850590\n",
       "3   44  78.112713\n",
       "4   43  78.243775\n",
       "5   42  78.636959\n",
       "6   41  79.816514\n",
       "7   40  79.554391\n",
       "8   39  79.685452\n",
       "9   38  80.340760\n",
       "10  37  80.602883\n",
       "11  36  80.209699\n",
       "12  35  80.078637\n",
       "13  34  80.209699\n",
       "14  33  80.209699\n",
       "15  32  80.471822\n",
       "16  31  80.471822\n",
       "17  30  80.733945\n",
       "18  29  80.340760\n",
       "19  28  80.865007\n",
       "20  27  80.996068\n",
       "21  26  81.389253\n",
       "22  25  81.782438\n",
       "23  24  81.651376\n",
       "24  23  82.306684\n",
       "25  22  81.782438\n",
       "26  21  82.175623\n",
       "27  20  81.389253\n",
       "28  19  80.733945\n",
       "29  18  80.996068\n",
       "30  17  80.340760\n",
       "31  16  79.554391\n",
       "32  15  79.947575\n",
       "33  14  79.816514\n",
       "34  13  79.947575\n",
       "35  12  79.947575\n",
       "36  11  79.816514\n",
       "37  10  80.602883\n",
       "38   9  82.699869\n",
       "39   8  83.224115\n",
       "40   7  85.583224\n",
       "41   6  87.680210\n",
       "42   5  88.728702\n",
       "43   4  90.170380\n",
       "44   3  92.267366\n",
       "45   2  94.102228"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for k in range(k_neighbors, 1, -1):\n",
    "    looped_knn = KNeighborsClassifier(n_neighbors=k).fit(x_over_train, y_over_train)\n",
    "    results.append(\n",
    "        {\n",
    "            'k': k,\n",
    "            'accuracy': accuracy_score(y_over_test, looped_knn.predict(x_over_test)) * 100\n",
    "        }\n",
    "    )\n",
    "results_df = pandas.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ace323",
   "metadata": {},
   "source": [
    "Use the values in `results_df` to create a scatter plot, using the built in `plot.scatter` method from `pandas`. Use `matplotlib.pyplot` to provide the necessary labels. Adding `xticks` will make the x-axis easier to read.\n",
    "\n",
    "The graph shows the accuracy scores for each of the trained models. It levels out at 10 or 11 neighbors. This means that 11 is likely the best choice for the number of neighbors, providing an accuracy rate of approximately 80%.\n",
    "\n",
    "One last thought on this model, since the `Response` values are binary in nature, it is likely that 2 neighbors is all that is wanted. This would strictly divide the data based on the 2 possible outcomes, which would improve the accuracy of the trained model to ~94%. However, it is also likely that with only 2 neighbors, the data would be over-fitted to the model, and any new data would not be easily identified. It also means that there would be issues with any tie-breaking that needed to occur, when assigning new values to the correct group. It is also likely that the K-Nearest Neighbors model is not a good choice for these kinds of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c283182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k_start = results_df.k.min()\n",
    "k_end = results_df.k.max() + 1\n",
    "results_df.plot.scatter(x=\"k\", y=\"accuracy\")\n",
    "matplotlib.pyplot.title(\"Accuracy Score Values by KNeighbors\")\n",
    "matplotlib.pyplot.xlabel(\"KNeighbors\")\n",
    "matplotlib.pyplot.ylabel(\"Accuracy Value\")\n",
    "matplotlib.pyplot.xticks(range(k_start, k_end))\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48265a7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
